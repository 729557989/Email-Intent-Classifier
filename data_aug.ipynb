{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the nlpaug library @ https://github.com/makcedward/nlpaug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessing import clean_df, map_labels\n",
    "import pandas as pd\n",
    "import config\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "from textblob import TextBlob\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Loaded label dict!\n"
     ]
    }
   ],
   "source": [
    "from Label2Id import Label2Id\n",
    "label_tknz = Label2Id()\n",
    "label_tknz.load_dict(config.gp_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/19/2022 11:27:16 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextToText, TTSettings\n",
    "happy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\n",
    "args = TTSettings(num_beams=5, min_length=1)\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"substitute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_label_dfs(raw_df, label_tknz, label_loc):\n",
    "    labels = list(label_tknz.dict.keys())\n",
    "    # a list of dataframes storing only instances of data belonging to one specific class/label\n",
    "    label_dataframes = {}\n",
    "    for label in labels:\n",
    "        label_dataframes[label] = raw_df.loc[raw_df[label_loc] == label]\n",
    "    return label_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi there we were not sure of the definition of low income for ny city so we did not check off that box on the application is there an income number that you use thanks julian'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dfs['monetary_issues'].iloc[0]['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hi there, we were not sure about the existence of double income for New York and so we could not check off that number on the left by there this income number that you use monthly.\",monetary_issues\n",
    "\n",
    "1,\"Hi, hope we were not certain of his definition of low income lower ny city so we did not break off that box on their application form for an area number that you use thanks.\",monetary_issues\n",
    "\n",
    "2,\"Go there we were not asking what the definition of fixed income little ny city was, so we did not check off that box on the left is there an elevator number who you use thanks now.\",monetary_issues\n",
    "\n",
    "3,But then we were most sure exactly the definition with low income for ny city so we did not exist for that but on the application is listed an income number that you use from julian.,monetary_issues\n",
    "\n",
    "4,\"Hi bad, we were not proud of that definition for zero income for ny city so we chose not to switch off each box on our application. Is there an application number that you use? Thanks Julian!\",monetary_issues\n",
    "\n",
    "5,\"Hi there, we heard almost sure the current definition of fixed income southern ny city so we did not check off that box on goose application. Is there an id number that you use like today?\",monetary_issues\n",
    "\n",
    "6,\"Hi there, we were not sure if the definition of low level for ny city us also did not check door to box because either application is there middle income number that you use thanks Julian.\",monetary_issues\n",
    "\n",
    "7,\"Hi Mike, we were pretty sure of the truth of a code for New York City so why did not check off that box on the rear is the an exact code that you use thanks Julian!\",monetary_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(config.data_path)\n",
    "df = clean_df(df, config.input_loc, config.columns_to_drop)\n",
    "df[config.label_loc] = df[config.label_loc].apply(map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['monetary_issues', 'program_info', 'unactionable', 'registration', 'program_logistics', 'scholarship', 'others'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dfs = get_specific_label_dfs(df, label_tknz, config.label_loc)\n",
    "label_tknz.dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['registration', 'program_logistics', 'scholarship', 'others'] # do 'unactionable' later\n",
    "def save_aug(target_save_labels, aug_size, df, label_tknz, label_dfs, args, aug_model):\n",
    "    aug_size = 4\n",
    "    for label in target_save_labels:\n",
    "        # max_instance = max_instance = int((df.shape[0] * aug_size)/len(label_tknz))\n",
    "        # n = max_instance // label_dfs[label].shape[0]\n",
    "        folder_path = \"NLP_augmented\"\n",
    "        saving_path = (folder_path + \"/\" + label + \".csv\")\n",
    "\n",
    "        temp_df = pd.DataFrame(columns=['augmented_text', 'label'])\n",
    "        for i in range(label_dfs[label].shape[0]):\n",
    "            print(f\"Processing the {i}th text, total: {label_dfs[label].shape[0]}\")\n",
    "            text = label_dfs[label].iloc[i][config.input_loc]\n",
    "            label = label_dfs[label].iloc[i][config.label_loc]\n",
    "\n",
    "            augmented_text = aug_model.augment(text,n=8)\n",
    "            for t in augmented_text:\n",
    "                t = TextBlob(t)\n",
    "                result = happy_tt.generate_text(\"grammar: \" + str(t.correct()), args=args)\n",
    "                temp_df = temp_df.append({\n",
    "                    'augmented_text': result.text,\n",
    "                    'label': label\n",
    "                },ignore_index=True)\n",
    "        temp_df.to_csv(saving_path)\n",
    "        print(f\"Successfully Saved Augmented DataFrame to {saving_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_aug(['registration'], 4, df, label_tknz, label_dfs, args, aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_df_from_folder(folder_path):\n",
    "   folder_path = \"NLP_augmented\"\n",
    "   df = pd.DataFrame()\n",
    "   for csv in os.listdir(folder_path):\n",
    "      csv_path = folder_path + \"/\" + csv\n",
    "      temp_df = pd.read_csv(csv_path)\n",
    "      try:\n",
    "         temp_df = temp_df[['augmented_text', 'label']]\n",
    "         temp_df = temp_df.rename(columns={\n",
    "            'augmented_text': 'input',\n",
    "            'label' : 'output'\n",
    "         })\n",
    "      except:\n",
    "         temp_df = temp_df[['input', 'output']]\n",
    "      df = pd.concat([df, temp_df], ignore_index=True)\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df_from_folder(\"NLP_augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "program_info         808\n",
       "monetary_issues      639\n",
       "unactionable         419\n",
       "registration         117\n",
       "others               117\n",
       "scholarship           92\n",
       "program_logistics     84\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdbc97045afd96267867941846430993b265c2648b2887872026f8e143bc3ea4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlpaug': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
